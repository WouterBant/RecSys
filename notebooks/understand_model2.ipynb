{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"clean/RecSys/code/\")  # for lightning env\n",
    "sys.path.append(\"../RecSys/code/\")  # locally\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # going to depreciate warnings, provided conda env works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MT5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "# model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\", output_attentions=True)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ArgsVal:\n",
    "    dataset: str = \"demo\"\n",
    "    batch_size: int = 1\n",
    "    num_workers: int = 4\n",
    "    T: int = 4  # number of previous articles to consider in the prompt\n",
    "    datafraction: float = 1.0  # how much of entire dataset to use\n",
    "    old: bool = True  # load checkpoints for model and not via modelwrapper\n",
    "    from_checkpoint: str = \"checkpoints/model_0.0001.pth\"  # path to checkpoint locally\n",
    "    model: str = \"CG\"  # conditional generation\n",
    "    backbone: str = \"google/mt5-small\"\n",
    "    tokenizer: str = \"google/mt5-small\"\n",
    "    evaltrain: bool = False  # allows for evaluation on training set\n",
    "    use_QA_model: bool = False\n",
    "\n",
    "@dataclass\n",
    "class ArgsTrain(ArgsVal):\n",
    "    evaltrain: bool = True  # allows for evaluation on training set\n",
    "\n",
    "argsval = ArgsVal()\n",
    "argstrain = ArgsTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "# model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\", output_attentions=True)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maart\\Documents\\RecSys\\RecSys\\code\n"
     ]
    }
   ],
   "source": [
    "%cd ../code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from models.get_model import get_model\n",
    "\n",
    "model_val = get_model(argsval)\n",
    "model_train = get_model(argstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CG_model(\n",
       "  (model): MT5ForConditionalGeneration(\n",
       "    (shared): Embedding(250112, 512)\n",
       "    (encoder): MT5Stack(\n",
       "      (embed_tokens): Embedding(250112, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): MT5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): MT5Stack(\n",
       "      (embed_tokens): Embedding(250112, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerCrossAttention(\n",
       "              (EncDecAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerCrossAttention(\n",
       "              (EncDecAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): MT5LayerFF(\n",
       "              (DenseReluDense): MT5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): MT5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       "  )\n",
       "  (ce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the prompt to use\n",
    "# the provided checkpoints was trained using subtitles\n",
    "from utils.prompt_templates import create_prompt_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd clean/RecSys/code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "from data.dataloader import EkstraBladetDataset\n",
    "\n",
    "# split sets output form of model\n",
    "data_val = EkstraBladetDataset(argsval, create_prompt_subtitles, split=\"validation\")\n",
    "data_train = EkstraBladetDataset(argstrain, create_prompt_subtitles, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model cannot process lists of strings\n",
    "# the collator tokenizes these inputs and creates tensors\n",
    "from collators import CollatorUnderstand\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(argsval.tokenizer)\n",
    "collator = CollatorUnderstand(tokenizer)\n",
    "dl_val = DataLoader(data_val, batch_size=1, collate_fn=collator, shuffle=False)\n",
    "dl_train = DataLoader(data_train, batch_size=1, collate_fn=collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt_input_ids': tensor([[  642, 36428,   588,  ...,     0,     0,     0],\n",
       "         [  642, 36428,   588,  ...,     0,     0,     0],\n",
       "         [  642, 36428,   588,  ...,     0,     0,     0],\n",
       "         [  642, 36428,   588,  ...,     0,     0,     0],\n",
       "         [  642, 36428,   588,  ...,  2794,   271,     1],\n",
       "         [  642, 36428,   588,  ...,     0,     0,     0]]),\n",
       " 'prompt_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'decoder_start': tensor([[ 432,  259,  275, 3810,    1],\n",
       "         [ 432,  259,  275, 3810,    1],\n",
       "         [ 432,  259,  275, 3810,    1],\n",
       "         [ 432,  259,  275, 3810,    1],\n",
       "         [ 432,  259,  275, 3810,    1],\n",
       "         [ 432,  259,  275, 3810,    1]]),\n",
       " 'targets': [0, 0, 0, 0, 0, 1],\n",
       " 'categories': ['nyheder',\n",
       "  'nationen',\n",
       "  'sport',\n",
       "  'nyheder',\n",
       "  'nyheder',\n",
       "  'forbrug',\n",
       "  'forbrug',\n",
       "  'underholdning',\n",
       "  'nyheder',\n",
       "  'sport'],\n",
       " 'prompts': ['En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen En kinesisk forsker har måske afsløret, at Kina tog teori om laboratorielæk mere alvorligt end hidtil antaget? (ja/nej)\\n',\n",
       "  'En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen Kursen på den svenske krone har stort set aldrig været så lav, som den er nu. Det kan danskerne drage nytte af. Ekstra Bladet har undersøgt, hvor de store besparelser kan findes? (ja/nej)\\n',\n",
       "  'En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen Milliardærklubben-værten og topøkonom Andreas Steno afslører, hvordan man på en smart måde kan forvalte sin formue midt i en krisetid? (ja/nej)\\n',\n",
       "  \"En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen Mars kører stort forsøg i England, hvor herligheden skal i en miljøvenlig papirindpakning i stedet for plastik. Herhjemme må vi dog vente lidt endnu, men 'man tripper', siger Mars Danmark? (ja/nej)\\n\",\n",
       "  'En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen Claus Jensen har haft lysten til at være nøgen foran andre, siden han var tretten år. Han ved godt, at det kan være både grænseoverskridende og skræmmende for dem, han møder på sin vej - men det er ikke meningen. Claus vil ikke forskrække nogen. Han tænder bare på at blive set? (ja/nej)\\n',\n",
       "  'En bruger har for nylig læst artikler: Andelen af elever med høj trivsel er faldet til 87,4 procent, Heftig debat om at leve uden sex. Mange - både kvinder og mæ, Fra 2026 skal Honda levere motorer til Aston Martin, som der, Planen lød blandt andet på at angribe fængselsbetjente med p, vil brugeren læse artiklen Ivan Toney er blevet straffet af det engelske fodboldforbund for blandt andet at have spillet mod sit eget hold? (ja/nej)\\n']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt_input_ids: tokenized prompts\n",
    "# prompt_attention_mask: make each element in the batch as long as the longest tokenized prompt, mask padding tokens\n",
    "# decoder_start: tokenized 'ja / nej' for CG modele\n",
    "example = next(iter(dl_val))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: inview that has been clicked is more likely to be chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_prefix(input_string):\n",
    "    start_phrase = \"vil brugeren læse artiklen\"\n",
    "    end_phrase = \"? (ja/nej)\"\n",
    "\n",
    "    start_index = input_string.find(start_phrase)\n",
    "    if start_index == -1:\n",
    "        return \"Start phrase not found\"\n",
    "    \n",
    "    prefix_text = input_string[:start_index].strip()\n",
    "    \n",
    "    start_index += len(start_phrase)\n",
    "\n",
    "    end_index = input_string.find(end_phrase, start_index)\n",
    "    if end_index == -1:\n",
    "        return \"End phrase not found\"\n",
    "\n",
    "    extracted_text = input_string[start_index:end_index].strip()\n",
    "    return prefix_text, extracted_text\n",
    "\n",
    "def check_recurrence(prefix_text, extracted_text):\n",
    "    return extracted_text in prefix_text\n",
    "\n",
    "def process_batch(example):\n",
    "    return [1 if check_recurrence(*extract_text_with_prefix(prompt)) else 0 for prompt in example['prompts']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and calculate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.0033834010976930115, pvalue=0.24080274385337955)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def forward_baseline_untrained(baseline_model, batch, device='cuda:0'):\n",
    "    with torch.no_grad():\n",
    "        outputs = baseline_model(\n",
    "            input_ids=batch[\"prompt_input_ids\"].to(device), \n",
    "            attention_mask=batch[\"prompt_attention_mask\"].to(device),\n",
    "            decoder_input_ids=batch[\"decoder_start\"].to(device)\n",
    "        )\n",
    "\n",
    "    ja_token_id = tokenizer.convert_tokens_to_ids('ja')\n",
    "    # Only take the first token (should be 'ja' or 'nej')\n",
    "    logits = outputs.logits[:,0,:]  # B, T, V -> B, V\n",
    "\n",
    "    # 36339 is the token id for 'ja'\n",
    "    probs = torch.softmax(logits, dim=-1)[:, ja_token_id]  # B, V -> B\n",
    "    return probs\n",
    "\n",
    "\n",
    "def run_CG_and_recurrence(model_val, dl_val, i=100, baseline=False):\n",
    "    recurrences = []\n",
    "    predictions = []\n",
    "    baseline_predictions = []\n",
    "    threshold = 0.5\n",
    "    for example in dl_val:\n",
    "        recurrence = process_batch(example)\n",
    "        probs = model_val.validation_step(example)\n",
    "        binary_predictions = torch.where(probs >= threshold, torch.tensor(1, device=probs.device), torch.tensor(0, device=probs.device))\n",
    "        if baseline:\n",
    "            baseline_probs = forward_baseline_untrained(baseline, example)\n",
    "            binary_baseline_predictions = torch.where(baseline_probs >= threshold, torch.tensor(1, device=baseline_probs.device), torch.tensor(0, device=baseline_probs.device))\n",
    "            baseline_predictions += binary_baseline_predictions.tolist()\n",
    "        recurrences += recurrence\n",
    "        predictions += binary_predictions.tolist()\n",
    "        i -= 1\n",
    "        if i == 0 and baseline:\n",
    "            return pearsonr(recurrences, predictions), pearsonr(recurrences, baseline_predictions)\n",
    "        elif i == 0:\n",
    "            return pearsonr(recurrences, predictions) \n",
    "        \n",
    "# model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small').to('cuda:0')\n",
    "run_CG_and_recurrence(model_val, dl_val, i=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

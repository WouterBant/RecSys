{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecSys\tclean  demo_data  main.py  new\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "sys.path.append('RecSys/code')  # for lightning ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from prompt_templates import create_prompt_titles\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    dataset = \"demo\"\n",
    "    batch_size = 1\n",
    "    num_workers = 4\n",
    "    T = 4\n",
    "    datafraction = 1.0\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Type(Enum):\n",
    "    IDS = 0\n",
    "    CATEGORIES = 1\n",
    "    PUBLISHED_TIME = 2\n",
    "    LAST_MODIFIED_TIME = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EkstraBladetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, args, create_prompt, type, split=\"train\"):\n",
    "        \n",
    "        # Download the dataset from huggingface\n",
    "        if split == \"test\":\n",
    "            self.behaviors = load_dataset(f'Wouter01/testbehaviors', cache_dir=f\"../../testbehaviors_data\")[\"train\"]\n",
    "            self.articles = load_dataset(f'Wouter01/testarticles', cache_dir=f\"../../testarticles_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/testhistory', cache_dir=f\"../../testhistory_data\")[\"train\"].to_pandas()\n",
    "        else:\n",
    "            self.behaviors = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'behaviors', cache_dir=f\"../{args.dataset}_data\")[split]\n",
    "            # self.articles = load_dataset(f'Wouter01/testdemoarticles', cache_dir=f\"../../{args.dataset}_data2\")[\"train\"].to_pandas()  #only use this for last modified time\n",
    "            self.articles = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'articles', cache_dir=f\"../{args.dataset}_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'history', cache_dir=f\"../{args.dataset}_data\")[split].to_pandas()\n",
    "\n",
    "        # Set fast lookup for identifier keys\n",
    "        self.history.set_index(\"user_id\", inplace=True)\n",
    "        self.articles.set_index(\"article_id\", inplace=True)\n",
    "\n",
    "        self.T = args.T  # Number of previous clicked articles to consider\n",
    "        self.create_prompt = create_prompt  # Function to create a prompt from the data\n",
    "        self.type = type\n",
    "        self.datafraction = args.datafraction\n",
    "        self.split = split\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.datafraction*len(self.behaviors))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Every item consits of a positive and negative sample\n",
    "        behavior = self.behaviors[idx]\n",
    "\n",
    "        # Get the inview articles\n",
    "        inview_articles = behavior[\"article_ids_inview\"]\n",
    "\n",
    "        # Get the history of the user\n",
    "        user_id = behavior[\"user_id\"]\n",
    "        history = self.history.loc[user_id]\n",
    "\n",
    "        # Get the T latest clicked articles by the user\n",
    "        old_clicks = history[\"article_id_fixed\"]\n",
    "        old_clicks = old_clicks[-min(len(old_clicks), self.T):]\n",
    "\n",
    "        # Pick random positive and negative samples\n",
    "        clicked_articles = behavior[\"article_ids_clicked\"]\n",
    "        unclicked_articles = [article for article in inview_articles if article not in clicked_articles]\n",
    "        pos_sample = random.choice(clicked_articles)\n",
    "\n",
    "        # If all documents clicked just treat one of them as a negative sample\n",
    "        if len(unclicked_articles) == 0:\n",
    "            unclicked_articles = clicked_articles\n",
    "        neg_sample = random.choice(unclicked_articles)\n",
    "\n",
    "        if self.type == Type.IDS:\n",
    "            old_clicks = old_clicks.tolist()\n",
    "        if self.type == Type.CATEGORIES:\n",
    "            old_clicks = [self.articles.loc[c][\"category_str\"] for c in old_clicks]\n",
    "            pos_sample = self.articles.loc[pos_sample][\"category_str\"]\n",
    "            neg_sample = self.articles.loc[neg_sample][\"category_str\"]\n",
    "        elif self.type == Type.PUBLISHED_TIME:\n",
    "            old_clicks = [self.articles.loc[c][\"published_time\"] for c in old_clicks]\n",
    "            pos_sample = self.articles.loc[pos_sample][\"published_time\"]\n",
    "            neg_sample = self.articles.loc[neg_sample][\"published_time\"]\n",
    "        elif self.type == Type.LAST_MODIFIED_TIME:\n",
    "            # make sure to comment out the line with the articles dataset above\n",
    "            try:\n",
    "                old_clicks = [self.articles.loc[c][\"last_modified_time\"] for c in old_clicks]\n",
    "                pos_sample = self.articles.loc[pos_sample][\"last_modified_time\"]\n",
    "                neg_sample = self.articles.loc[neg_sample][\"last_modified_time\"]\n",
    "            except:\n",
    "                raise ValueError(\"make sure to comment out the line with the articles dataset above\")\n",
    "\n",
    "        return old_clicks, pos_sample, neg_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, backoff=False, generalize=False, penalize_negative=0.0):\n",
    "    model = defaultdict(lambda: defaultdict(int))\n",
    "    random.seed(42)\n",
    "    for old_clicks, pos_sample, neg_sample in tqdm(data):\n",
    "        history_length = len(old_clicks)\n",
    "        for length in range(history_length, 0, -1):\n",
    "            if generalize:\n",
    "                # create a pattern eg:\n",
    "                #  [1,2,4,2,1,4] --> [1,2,3,2,1,3]\n",
    "                #  [7,5,4,5,7,5] --> [1,2,3,2,1,3]\n",
    "                p2i = {}\n",
    "                i = 1\n",
    "                for p in old_clicks[-length:]:\n",
    "                    if p not in p2i:\n",
    "                        p2i[p] = i\n",
    "                        i += 1\n",
    "                old_clicks = tuple([p2i[p] for p in old_clicks[-length:]])\n",
    "            else:\n",
    "                old_clicks = tuple(old_clicks[-length:])\n",
    "            model[old_clicks][pos_sample] += 1\n",
    "            model[old_clicks][neg_sample] -= penalize_negative\n",
    "            if not backoff:\n",
    "                break\n",
    "    return model\n",
    "\n",
    "def evaluate(model, data, backoff=False, generalize=False):\n",
    "    random.seed(42) \n",
    "    correct = tie = lose = total = 0\n",
    "    for old_clicks, pos_sample, neg_sample in tqdm(data):\n",
    "        history_length = len(old_clicks)\n",
    "        for length in range(history_length, 0, -1):\n",
    "            if generalize:\n",
    "                p2i = {}\n",
    "                i = 1\n",
    "                for p in old_clicks[-length:]:\n",
    "                    if p not in p2i:\n",
    "                        p2i[p] = i\n",
    "                        i += 1\n",
    "                old_clicks = tuple([p2i[p] for p in old_clicks[-length:]])\n",
    "            else:\n",
    "                old_clicks = tuple(old_clicks[-length:])\n",
    "            if model[old_clicks][pos_sample] > model[old_clicks][neg_sample]:\n",
    "                correct += 1\n",
    "            elif model[old_clicks][pos_sample] < model[old_clicks][neg_sample]:\n",
    "                lose += 1\n",
    "            else:  # Tie\n",
    "                if backoff:\n",
    "                    if length == 1:\n",
    "                        tie += 1\n",
    "                    continue\n",
    "                tie += 1\n",
    "                break\n",
    "            break\n",
    "        total += 1\n",
    "    return correct, tie, lose, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: Type.IDS, Backoff: False, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6345.59it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6469.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.IDS, Backoff: False, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6547.83it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6392.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.IDS, Backoff: False, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6567.72it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6386.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.IDS, Backoff: False, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6510.16it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6411.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 749, Tie: 22556, Lose: 2051, Total: 25356, Accuracy: 0.47432560340747754\n",
      "Type: Type.IDS, Backoff: False, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6542.35it/s]\n",
      "100%|██████████| 25356/25356 [00:04<00:00, 6256.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2345, Tie: 21134, Lose: 1877, Total: 25356, Accuracy: 0.5092285849503077\n",
      "Type: Type.IDS, Backoff: False, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6450.67it/s]\n",
      "100%|██████████| 25356/25356 [00:04<00:00, 6237.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2762, Tie: 21267, Lose: 1327, Total: 25356, Accuracy: 0.5282970500078876\n",
      "Type: Type.IDS, Backoff: True, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6425.49it/s]\n",
      "100%|██████████| 25356/25356 [00:04<00:00, 6254.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 5, Tie: 25343, Lose: 8, Total: 25356, Accuracy: 0.4999408424041647\n",
      "Type: Type.IDS, Backoff: True, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6420.64it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6408.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 9, Tie: 25338, Lose: 9, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.IDS, Backoff: True, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6529.35it/s]\n",
      "100%|██████████| 25356/25356 [00:04<00:00, 5815.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 9, Tie: 25338, Lose: 9, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.IDS, Backoff: True, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6342.13it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6354.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 867, Tie: 21890, Lose: 2599, Total: 25356, Accuracy: 0.4658463480044171\n",
      "Type: Type.IDS, Backoff: True, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6315.92it/s]\n",
      "100%|██████████| 25356/25356 [00:03<00:00, 6398.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2758, Tie: 20494, Lose: 2104, Total: 25356, Accuracy: 0.5128963558920966\n",
      "Type: Type.IDS, Backoff: True, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:03<00:00, 6452.77it/s]\n",
      "100%|██████████| 25356/25356 [00:04<00:00, 6192.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 3245, Tie: 20601, Lose: 1510, Total: 25356, Accuracy: 0.5342128095914183\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1890.98it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1835.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 5797, Tie: 14551, Lose: 5008, Total: 25356, Accuracy: 0.5155584477046853\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1885.19it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1822.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 6201, Tie: 13801, Lose: 5354, Total: 25356, Accuracy: 0.5167021612241679\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1857.76it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1838.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 5993, Tie: 14221, Lose: 5142, Total: 25356, Accuracy: 0.516781038018615\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1773.56it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1845.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10528, Tie: 4922, Lose: 9906, Total: 25356, Accuracy: 0.5122653415365199\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1826.39it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1864.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10529, Tie: 4921, Lose: 9906, Total: 25356, Accuracy: 0.5122850607351317\n",
      "Type: Type.CATEGORIES, Backoff: False, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1853.72it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1908.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10524, Tie: 5196, Lose: 9636, Total: 25356, Accuracy: 0.5175106483672504\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1851.94it/s]\n",
      "100%|██████████| 25356/25356 [00:14<00:00, 1809.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10869, Tie: 5024, Lose: 9463, Total: 25356, Accuracy: 0.5277251932481464\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1864.06it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1820.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10839, Tie: 5016, Lose: 9501, Total: 25356, Accuracy: 0.5263842877425462\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:13<00:00, 1887.02it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1823.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10806, Tie: 5103, Lose: 9447, Total: 25356, Accuracy: 0.5267983909133933\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:14<00:00, 1703.25it/s]\n",
      "100%|██████████| 25356/25356 [00:18<00:00, 1361.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10530, Tie: 4919, Lose: 9907, Total: 25356, Accuracy: 0.5122850607351317\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:12<00:00, 1967.17it/s]\n",
      "100%|██████████| 25356/25356 [00:10<00:00, 2348.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10529, Tie: 4919, Lose: 9908, Total: 25356, Accuracy: 0.5122456223379082\n",
      "Type: Type.CATEGORIES, Backoff: True, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:10<00:00, 2272.77it/s]\n",
      "100%|██████████| 25356/25356 [00:10<00:00, 2364.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 10665, Tie: 4919, Lose: 9772, Total: 25356, Accuracy: 0.5176092443603092\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:12<00:00, 1999.63it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1918.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:12<00:00, 2003.60it/s]\n",
      "100%|██████████| 25356/25356 [00:12<00:00, 1997.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2209.70it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1891.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 0, Tie: 25356, Lose: 0, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2173.08it/s]\n",
      "100%|██████████| 25356/25356 [00:12<00:00, 2080.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 749, Tie: 22556, Lose: 2051, Total: 25356, Accuracy: 0.47432560340747754\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2075.33it/s]\n",
      "100%|██████████| 25356/25356 [00:11<00:00, 2182.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2345, Tie: 21134, Lose: 1877, Total: 25356, Accuracy: 0.5092285849503077\n",
      "Type: Type.PUBLISHED_TIME, Backoff: False, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2103.81it/s]\n",
      "100%|██████████| 25356/25356 [00:12<00:00, 1990.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2762, Tie: 21267, Lose: 1327, Total: 25356, Accuracy: 0.5282970500078876\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: False, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2176.37it/s]\n",
      "100%|██████████| 25356/25356 [00:12<00:00, 2088.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 5, Tie: 25343, Lose: 8, Total: 25356, Accuracy: 0.4999408424041647\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: False, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2207.94it/s]\n",
      "100%|██████████| 25356/25356 [00:12<00:00, 2094.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 9, Tie: 25338, Lose: 9, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: False, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2107.19it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1912.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 9, Tie: 25338, Lose: 9, Total: 25356, Accuracy: 0.5\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: True, Penalize negative: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:12<00:00, 1905.91it/s]\n",
      "100%|██████████| 25356/25356 [00:13<00:00, 1849.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 867, Tie: 21890, Lose: 2599, Total: 25356, Accuracy: 0.4658463480044171\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: True, Penalize negative: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:12<00:00, 1959.98it/s]\n",
      "100%|██████████| 25356/25356 [00:11<00:00, 2218.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 2758, Tie: 20494, Lose: 2104, Total: 25356, Accuracy: 0.5128963558920966\n",
      "Type: Type.PUBLISHED_TIME, Backoff: True, Generalize: True, Penalize negative: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24724/24724 [00:11<00:00, 2192.94it/s]\n",
      "100%|██████████| 25356/25356 [00:11<00:00, 2134.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Correct: 3245, Tie: 20601, Lose: 1510, Total: 25356, Accuracy: 0.5342128095914183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for type in (Type.IDS, Type.CATEGORIES, Type.PUBLISHED_TIME):\n",
    "    train_data = EkstraBladetDataset(args, create_prompt_titles, type, split=\"train\")\n",
    "    val_data = EkstraBladetDataset(args, create_prompt_titles, type, split=\"validation\")\n",
    "    for backoff in (False, True):\n",
    "        for generalize in (False, True):\n",
    "            for penalize_negative in (0.0, 0.1, 0.5):\n",
    "                print(f\"Type: {type}, Backoff: {backoff}, Generalize: {generalize}, Penalize negative: {penalize_negative}\")\n",
    "                model = train(train_data, backoff, generalize, penalize_negative)\n",
    "                correct, tie, lose, total = evaluate(model, val_data, backoff, generalize)\n",
    "                print(f\"Validation: Correct: {correct}, Tie: {tie}, Lose: {lose}, Total: {total}, Accuracy: {(correct+0.5*tie)/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49767313456381135, 0.00015775358889414735, 0.5021691118472945)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate just predicting the latest\n",
    "val_data = EkstraBladetDataset(args, create_prompt_titles, Type.PUBLISHED_TIME, split=\"validation\")\n",
    "total = win = tie = lose = 0\n",
    "for old_clicks, pos_sample, neg_sample in val_data:\n",
    "\n",
    "    if pos_sample == None or neg_sample == None:\n",
    "        tie += 1\n",
    "        continue\n",
    "\n",
    "    if pos_sample > neg_sample:\n",
    "        win += 1\n",
    "    elif pos_sample == neg_sample:\n",
    "        tie += 1  # very unlikely\n",
    "    else:\n",
    "        lose += 1\n",
    "    total += 1\n",
    "win/total, tie/total, lose/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6505758005994636, 0.0, 0.3494241994005364)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# closest publish time to latest clicked article\n",
    "val_data = EkstraBladetDataset(args, create_prompt_titles, Type.PUBLISHED_TIME, split=\"validation\")\n",
    "total = win = tie = lose = 0\n",
    "for old_clicks, pos_sample, neg_sample in val_data:\n",
    "    latest = old_clicks[-1]\n",
    "    if latest == None or pos_sample == None or neg_sample == None:\n",
    "        tie += 1\n",
    "        continue\n",
    "\n",
    "    if abs(latest - pos_sample) < abs(latest - neg_sample):\n",
    "        win += 1\n",
    "    else:\n",
    "        lose += 1\n",
    "    total += 1\n",
    "win/total, tie/total, lose/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3686701181038667, 0.0, 0.6313298818961333)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last modified time negatively correlated with click\n",
    "val_data = EkstraBladetDataset(args, create_prompt_titles, Type.LAST_MODIFIED_TIME, split=\"train\")\n",
    "total = win = tie = lose = 0\n",
    "for old_clicks, pos_sample, neg_sample in val_data:\n",
    "    latest = old_clicks[-1]\n",
    "    if latest == None or pos_sample == None or neg_sample == None:\n",
    "        tie += 1\n",
    "        continue\n",
    "    \n",
    "    if pos_sample > neg_sample:\n",
    "        win += 1\n",
    "    # if abs(latest - pos_sample) < abs(latest - neg_sample):\n",
    "    #     win += 1\n",
    "    else:\n",
    "        lose += 1\n",
    "    total += 1\n",
    "win/total, tie/total, lose/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another simple policy is to recommend the most clicked article\n",
    "# count the clicks for each article in the dataset and use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the article that is most inview\n",
    "class Args:\n",
    "    dataset = \"demo\"\n",
    "    batch_size = 1\n",
    "    num_workers = 4\n",
    "    T = 100000\n",
    "    datafraction = 1.0\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Count(Dataset):\n",
    "\n",
    "    def __init__(self, args, create_prompt, type, split=\"train\"):\n",
    "        \n",
    "        # Download the dataset from huggingface\n",
    "        if split == \"test\":\n",
    "            self.behaviors = load_dataset(f'Wouter01/testbehaviors', cache_dir=f\"../../testbehaviors_data\")[\"train\"]\n",
    "            self.articles = load_dataset(f'Wouter01/testarticles', cache_dir=f\"../../testarticles_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/testhistory', cache_dir=f\"../../testhistory_data\")[\"train\"].to_pandas()\n",
    "        else:\n",
    "            self.behaviors = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'behaviors', cache_dir=f\"../../{args.dataset}_data\")[split]\n",
    "            self.articles = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'articles', cache_dir=f\"../../{args.dataset}_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'history', cache_dir=f\"../../{args.dataset}_data\")[split].to_pandas()\n",
    "\n",
    "        # Set fast lookup for identifier keys\n",
    "        self.history.set_index(\"user_id\", inplace=True)\n",
    "        self.articles.set_index(\"article_id\", inplace=True)\n",
    "\n",
    "        self.T = args.T  # Number of previous clicked articles to consider\n",
    "        self.create_prompt = create_prompt  # Function to create a prompt from the data\n",
    "        self.type = type\n",
    "        self.datafraction = args.datafraction\n",
    "        self.split = split\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.datafraction*len(self.behaviors))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Every item consits of a positive and negative sample\n",
    "        behavior = self.behaviors[idx]\n",
    "\n",
    "        # Get the inview articles\n",
    "        inview_articles = behavior[\"article_ids_inview\"]\n",
    "\n",
    "        return inview_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25356/25356 [00:01<00:00, 14054.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "304915"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = defaultdict(int)\n",
    "\n",
    "train_data = Count(args, create_prompt_titles, Type.IDS, split=\"validation\")\n",
    "for inview_articles in tqdm(train_data):\n",
    "    for article in inview_articles:\n",
    "        model[article] += 1\n",
    "sum(model.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5298548666982174, 0.0020507966556239155, 0.4680943366461587)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same for last modified time, have to upload this first\n",
    "val_data = EkstraBladetDataset(args, create_prompt_titles, Type.IDS, split=\"validation\")\n",
    "total = win = tie = lose = 0\n",
    "for _, pos_sample, neg_sample in val_data:\n",
    "    if model[pos_sample] > model[neg_sample]:\n",
    "        win += 1\n",
    "    elif model[pos_sample] == model[neg_sample]:\n",
    "        tie += 1\n",
    "    else:\n",
    "        lose += 1\n",
    "    total += 1\n",
    "win/total, tie/total, lose/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Count(Dataset):\n",
    "\n",
    "    def __init__(self, args, create_prompt, type, split=\"train\"):\n",
    "        \n",
    "        # Download the dataset from huggingface\n",
    "        if split == \"test\":\n",
    "            self.behaviors = load_dataset(f'Wouter01/testbehaviors', cache_dir=f\"../../testbehaviors_data\")[\"train\"]\n",
    "            self.articles = load_dataset(f'Wouter01/testarticles', cache_dir=f\"../../testarticles_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/testhistory', cache_dir=f\"../../testhistory_data\")[\"train\"].to_pandas()\n",
    "        else:\n",
    "            self.behaviors = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'behaviors', cache_dir=f\"../../{args.dataset}_data\")[split]\n",
    "            self.articles = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'articles', cache_dir=f\"../../{args.dataset}_data\")[\"train\"].to_pandas()\n",
    "            self.history = load_dataset(f'Wouter01/RecSys_{args.dataset}', 'history', cache_dir=f\"../../{args.dataset}_data\")[split].to_pandas()\n",
    "\n",
    "        # Set fast lookup for identifier keys\n",
    "        self.history.set_index(\"user_id\", inplace=True)\n",
    "        self.articles.set_index(\"article_id\", inplace=True)\n",
    "\n",
    "        self.T = args.T  # Number of previous clicked articles to consider\n",
    "        self.create_prompt = create_prompt  # Function to create a prompt from the data\n",
    "        self.type = type\n",
    "        self.datafraction = args.datafraction\n",
    "        self.split = split\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.datafraction*len(self.behaviors))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Every item consits of a positive and negative sample\n",
    "        behavior = self.behaviors[idx]\n",
    "\n",
    "        # Get the clicked articles\n",
    "        article_ids_clicked = behavior[\"article_ids_clicked\"]\n",
    "\n",
    "        return article_ids_clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25356/25356 [00:02<00:00, 10813.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25505"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = defaultdict(int)\n",
    "\n",
    "train_data = Count(args, create_prompt_titles, Type.IDS, split=\"validation\")\n",
    "for inview_articles in tqdm(train_data):\n",
    "    for article in inview_articles:\n",
    "        model[article] += 1\n",
    "sum(model.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6527843508439817, 0.017392333175579745, 0.32982331598043857)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same for last modified time, have to upload this first\n",
    "val_data = EkstraBladetDataset(args, create_prompt_titles, Type.IDS, split=\"validation\")\n",
    "total = win = tie = lose = 0\n",
    "for _, pos_sample, neg_sample in val_data:\n",
    "    if model[pos_sample] > model[neg_sample]:\n",
    "        win += 1\n",
    "    elif model[pos_sample] == model[neg_sample]:\n",
    "        tie += 1\n",
    "    else:\n",
    "        lose += 1\n",
    "    total += 1\n",
    "win/total, tie/total, lose/total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
